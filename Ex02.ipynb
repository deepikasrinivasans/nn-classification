{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Name: DEEPIKA S\n",
        "\n",
        "Register Number: 212222230028"
      ]
    },
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0420487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "import pickle\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data\n",
    "customer_df = pd.read_csv('customers.csv')\n",
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6faec14",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Exploration\n",
    "\n",
    "print(\"Columns in the dataset:\")\n",
    "print(customer_df.columns)\n",
    "\n",
    "print(\"\\nData types of each column:\")\n",
    "print(customer_df.dtypes)\n",
    "\n",
    "print(\"\\nShape of the dataset:\")\n",
    "print(customer_df.shape)\n",
    "\n",
    "print(\"\\nMissing values in each column:\")\n",
    "print(customer_df.isnull().sum())\n",
    "\n",
    "# Dropping rows with missing values\n",
    "customer_df_cleaned = customer_df.dropna(axis=0)\n",
    "print(\"\\nMissing values after cleaning:\")\n",
    "print(customer_df_cleaned.isnull().sum())\n",
    "print(\"\\nShape of cleaned dataset:\")\n",
    "print(customer_df_cleaned.shape)\n",
    "\n",
    "print(\"\\nData types of cleaned dataset:\")\n",
    "print(customer_df_cleaned.dtypes)\n",
    "\n",
    "print(\"\\nUnique values in columns:\")\n",
    "print(customer_df_cleaned[['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score', 'Var_1', 'Segmentation']].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e272d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical features\n",
    "categories_list = [['Male', 'Female'],\n",
    "                   ['No', 'Yes'],\n",
    "                   ['No', 'Yes'],\n",
    "                   ['Healthcare', 'Engineer', 'Lawyer', 'Artist', 'Doctor', 'Homemaker', 'Entertainment', 'Marketing', 'Executive'],\n",
    "                   ['Low', 'Average', 'High']]\n",
    "\n",
    "enc = OrdinalEncoder(categories=categories_list)\n",
    "customers_1 = customer_df_cleaned.copy()\n",
    "customers_1[['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score']] = enc.fit_transform(customers_1[['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Spending_Score']])\n",
    "\n",
    "le = LabelEncoder()\n",
    "customers_1['Segmentation'] = le.fit_transform(customers_1['Segmentation'])\n",
    "\n",
    "customers_1 = customers_1.drop(['ID', 'Var_1'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75829b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data visualization\n",
    "corr = customers_1.corr()\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(corr, xticklabels=corr.columns, yticklabels=corr.columns, cmap=\"BuPu\", annot=True)\n",
    "plt.show()\n",
    "\n",
    "sns.pairplot(customers_1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.distplot(customers_1['Age'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.countplot(customers_1['Family_Size'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.boxplot(x='Family_Size', y='Age', data=customers_1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Family_Size', y='Spending_Score', data=customers_1)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.scatterplot(x='Family_Size', y='Age', data=customers_1)\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nDescriptive statistics:\")\n",
    "print(customers_1.describe())\n",
    "\n",
    "print(\"\\nUnique values in 'Segmentation':\")\n",
    "print(customers_1['Segmentation'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238f11a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing data for model\n",
    "X = customers_1[['Gender', 'Ever_Married', 'Age', 'Graduated', 'Profession', 'Work_Experience', 'Spending_Score', 'Family_Size']].values\n",
    "y1 = customers_1[['Segmentation']].values\n",
    "\n",
    "one_hot_enc = OneHotEncoder()\n",
    "one_hot_enc.fit(y1)\n",
    "y = one_hot_enc.transform(y1).toarray()\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=50)\n",
    "\n",
    "# Scaling the Age feature\n",
    "scaler_age = MinMaxScaler()\n",
    "scaler_age.fit(X_train[:, 2].reshape(-1, 1))\n",
    "\n",
    "X_train_scaled = np.copy(X_train)\n",
    "X_test_scaled = np.copy(X_test)\n",
    "\n",
    "X_train_scaled[:, 2] = scaler_age.transform(X_train[:, 2].reshape(-1, 1)).reshape(-1)\n",
    "X_test_scaled[:, 2] = scaler_age.transform(X_test[:, 2].reshape(-1, 1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a46e40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training the model\n",
    "ai_brain = Sequential([\n",
    "    Dense(6, activation='relu', input_shape=[8]),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "ai_brain.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "history = ai_brain.fit(x=X_train_scaled, y=y_train, epochs=2000, batch_size=256, validation_data=(X_test_scaled, y_test), callbacks=[early_stop])\n",
    "\n",
    "# Plotting training metrics\n",
    "metrics = pd.DataFrame(history.history)\n",
    "plt.figure(figsize=(10,6))\n",
    "metrics[['loss', 'val_loss']].plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
